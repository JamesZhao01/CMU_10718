{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumping out of src\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "\n",
    "if not os.getcwd().endswith(\"src\"):\n",
    "    os.chdir(\"src\")\n",
    "    print(\"jumping into src\")\n",
    "\n",
    "from utils.data.data_module import DataModule\n",
    "from utils.data.testbench import TestBench\n",
    "from recommender.run_pipeline import Models\n",
    "\n",
    "if os.getcwd().endswith(\"src\"):\n",
    "    os.chdir(\"..\")\n",
    "    print(\"jumping out of src\")\n",
    "\n",
    "args = {\n",
    "    \"output_dir\": \"models/popularity\",\n",
    "    \"dataset_config\": \"configs/datasets/id_dataset.json\",\n",
    "    \"model_config\": \"configs/twotower/1_user_embedder_fresh.json\",\n",
    "    \"model\": \"tower\",\n",
    "    \"should_return_ids\": True,\n",
    "}\n",
    "dataset_config = {}\n",
    "model_config = {}\n",
    "output_dir = args[\"output_dir\"]\n",
    "if args[\"dataset_config\"]:\n",
    "    with open(args[\"dataset_config\"], \"r\") as f:\n",
    "        dataset_config_2 = json.load(f)\n",
    "        dataset_config.update(dataset_config_2)\n",
    "if args[\"model_config\"]:\n",
    "    with open(args[\"model_config\"], \"r\") as f:\n",
    "        model_config = json.load(f)\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing animes...: 100%|██████████| 12294/12294 [00:00<00:00, 13261.87it/s]\n",
      "Parsing users...: 100%|██████████| 73515/73515 [00:34<00:00, 2122.39it/s]\n",
      "Resetting Train to k=0 ...: 100%|██████████| 48669/48669 [00:13<00:00, 3662.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 54077, Hash[:8]: 9f0cd3, Hash: 9f0cd3119bd9ee7279856737c33aebb8\n",
      "Total Animes: 12294, Total Users: 54077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datamodule = DataModule(**dataset_config)\n",
    "testbench = TestBench(\n",
    "    datamodule, should_return_ids=args.get(\"should_return_ids\", False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:0.805, +:-0.008, -:-0.001: 100%|██████████| 106/106 [00:08<00:00, 12.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss: 0.8048. Time: 8.81 s / 176.19 s. ETA: 167.38 s\n",
      "Start Time: 2024-11-13 00:25:33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "User Embeddings...: 11it [00:00, 1571.27it/s]\n",
      "Anime Embeddings...: 100%|██████████| 25/25 [00:00<00:00, 238.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_embeddings.shape=(5408, 256) anime_embeddings.shape=(256, 12294)\n",
      "Commence God Operation\n",
      "Commence Big Sort Energy\n",
      "End Time: 2024-11-13 00:25:35\n",
      "This model took 1.7700 seconds.\n",
      "Out of an optimal score of 1.0, you scored 0.0006.\n",
      "Your DEI score is 87302.5098.\n",
      "Your Pseudo-IOU score is 0.2175.\n",
      ">>0|0.8033438920974731|{\"runtime\": 1.7699995040893555, \"ndcg\": 0.0006361818551816851, \"diversity_score\": 87302.50979741458, \"pseudo_iou\": 0.21749260355029587}<<\n",
      "Epoch 2 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:0.788, +:0.048, -:0.001: 100%|██████████| 106/106 [00:08<00:00, 12.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Loss: 0.7896. Time: 23.96 s / 239.62 s. ETA: 215.66 s\n",
      "Start Time: 2024-11-13 00:25:48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "User Embeddings...: 11it [00:00, 1571.49it/s]\n",
      "Anime Embeddings...: 100%|██████████| 25/25 [00:00<00:00, 227.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_embeddings.shape=(5408, 256) anime_embeddings.shape=(256, 12294)\n",
      "Commence God Operation\n",
      "Commence Big Sort Energy\n",
      "End Time: 2024-11-13 00:25:50\n",
      "This model took 1.7943 seconds.\n",
      "Out of an optimal score of 1.0, you scored 0.0006.\n",
      "Your DEI score is 87208.2939.\n",
      "Your Pseudo-IOU score is 0.2172.\n",
      ">>1|0.7850773930549622|{\"runtime\": 1.7942678928375244, \"ndcg\": 0.0005689330452788836, \"diversity_score\": 87208.29385646913, \"pseudo_iou\": 0.2172337278106509}<<\n",
      "Epoch 3 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:0.772, +:0.097, -:-0.006: 100%|██████████| 106/106 [00:08<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] Loss: 0.7725. Time: 39.09 s / 260.62 s. ETA: 221.53 s\n",
      "Start Time: 2024-11-13 00:26:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "User Embeddings...: 11it [00:00, 1571.01it/s]\n",
      "Anime Embeddings...: 100%|██████████| 25/25 [00:00<00:00, 74.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_embeddings.shape=(5408, 256) anime_embeddings.shape=(256, 12294)\n",
      "Commence God Operation\n",
      "Commence Big Sort Energy\n",
      "End Time: 2024-11-13 00:26:05\n",
      "This model took 2.0444 seconds.\n",
      "Out of an optimal score of 1.0, you scored 0.0006.\n",
      "Your DEI score is 87113.9970.\n",
      "Your Pseudo-IOU score is 0.2168.\n",
      ">>2|0.7714357376098633|{\"runtime\": 2.0444488525390625, \"ndcg\": 0.0006080715176186917, \"diversity_score\": 87113.99697403343, \"pseudo_iou\": 0.21682692307692308}<<\n",
      "Epoch 4 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:0.751, +:0.176, -:-0.001: 100%|██████████| 106/106 [00:08<00:00, 12.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Loss: 0.7532. Time: 54.24 s / 271.18 s. ETA: 216.94 s\n",
      "Start Time: 2024-11-13 00:26:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "User Embeddings...: 11it [00:00, 1832.30it/s]\n",
      "Anime Embeddings...: 100%|██████████| 25/25 [00:00<00:00, 238.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_embeddings.shape=(5408, 256) anime_embeddings.shape=(256, 12294)\n",
      "Commence God Operation\n",
      "Commence Big Sort Energy\n",
      "End Time: 2024-11-13 00:26:20\n",
      "This model took 1.8050 seconds.\n",
      "Out of an optimal score of 1.0, you scored 0.0009.\n",
      "Your DEI score is 87261.9534.\n",
      "Your Pseudo-IOU score is 0.2173.\n",
      ">>3|0.7528936266899109|{\"runtime\": 1.8049983978271484, \"ndcg\": 0.0009200002258237322, \"diversity_score\": 87261.9533750536, \"pseudo_iou\": 0.2172707100591716}<<\n",
      "Epoch 5 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:0.716, +:0.299, -:-0.023: 100%|██████████| 106/106 [00:09<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] Loss: 0.7228. Time: 69.80 s / 279.22 s. ETA: 209.41 s\n",
      "Start Time: 2024-11-13 00:26:34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "User Embeddings...: 11it [00:00, 1571.76it/s]\n",
      "Anime Embeddings...: 100%|██████████| 25/25 [00:00<00:00, 241.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_embeddings.shape=(5408, 256) anime_embeddings.shape=(256, 12294)\n",
      "Commence God Operation\n",
      "Commence Big Sort Energy\n",
      "End Time: 2024-11-13 00:26:36\n",
      "This model took 1.7879 seconds.\n",
      "Out of an optimal score of 1.0, you scored 0.0018.\n",
      "Your DEI score is 86483.7468.\n",
      "Your Pseudo-IOU score is 0.2146.\n",
      ">>4|0.7095122933387756|{\"runtime\": 1.7879269123077393, \"ndcg\": 0.0017950165053867131, \"diversity_score\": 86483.74682216218, \"pseudo_iou\": 0.2146449704142012}<<\n",
      "Epoch 6 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:0.666, +:0.500, -:-0.058: 100%|██████████| 106/106 [00:09<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] Loss: 0.6759. Time: 85.19 s / 283.98 s. ETA: 198.78 s\n",
      "Start Time: 2024-11-13 00:26:49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "User Embeddings...: 11it [00:00, 2199.84it/s]\n",
      "Anime Embeddings...: 100%|██████████| 25/25 [00:00<00:00, 231.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_embeddings.shape=(5408, 256) anime_embeddings.shape=(256, 12294)\n",
      "Commence God Operation\n",
      "Commence Big Sort Energy\n",
      "End Time: 2024-11-13 00:26:51\n",
      "This model took 1.8273 seconds.\n",
      "Out of an optimal score of 1.0, you scored 0.0054.\n",
      "Your DEI score is 83449.9444.\n",
      "Your Pseudo-IOU score is 0.2056.\n",
      ">>5|0.6585985422134399|{\"runtime\": 1.827345371246338, \"ndcg\": 0.005368826269059618, \"diversity_score\": 83449.94444263619, \"pseudo_iou\": 0.20560281065088756}<<\n",
      "Epoch 7 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:0.592, +:0.815, -:-0.153: 100%|██████████| 106/106 [00:09<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] Loss: 0.6051. Time: 100.93 s / 288.36 s. ETA: 187.43 s\n",
      "Start Time: 2024-11-13 00:27:05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "User Embeddings...: 11it [00:00, 2200.47it/s]\n",
      "Anime Embeddings...: 100%|██████████| 25/25 [00:00<00:00, 231.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_embeddings.shape=(5408, 256) anime_embeddings.shape=(256, 12294)\n",
      "Commence God Operation\n",
      "Commence Big Sort Energy\n",
      "End Time: 2024-11-13 00:27:07\n",
      "This model took 1.8448 seconds.\n",
      "Out of an optimal score of 1.0, you scored 0.0131.\n",
      "Your DEI score is 70124.5603.\n",
      "Your Pseudo-IOU score is 0.1677.\n",
      ">>6|0.5942761898040771|{\"runtime\": 1.8448255062103271, \"ndcg\": 0.013063999471592288, \"diversity_score\": 70124.56025884724, \"pseudo_iou\": 0.16773298816568047}<<\n",
      "Epoch 8 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:0.500, +:1.256, -:-0.336: 100%|██████████| 106/106 [00:08<00:00, 12.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] Loss: 0.5168. Time: 116.27 s / 290.68 s. ETA: 174.41 s\n",
      "Start Time: 2024-11-13 00:27:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "User Embeddings...: 11it [00:00, 2199.74it/s]\n",
      "Anime Embeddings...: 100%|██████████| 25/25 [00:00<00:00, 71.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_embeddings.shape=(5408, 256) anime_embeddings.shape=(256, 12294)\n",
      "Commence God Operation\n",
      "Commence Big Sort Energy\n",
      "End Time: 2024-11-13 00:27:22\n",
      "This model took 2.0648 seconds.\n",
      "Out of an optimal score of 1.0, you scored 0.0207.\n",
      "Your DEI score is 39678.2201.\n",
      "Your Pseudo-IOU score is 0.0843.\n",
      ">>7|0.5034070611000061|{\"runtime\": 2.0648105144500732, \"ndcg\": 0.020691533036280442, \"diversity_score\": 39678.22014551177, \"pseudo_iou\": 0.08426405325443787}<<\n",
      "Epoch 9 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:0.413, +:1.707, -:-0.616: 100%|██████████| 106/106 [00:08<00:00, 12.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] Loss: 0.4300. Time: 131.62 s / 292.49 s. ETA: 160.87 s\n",
      "Start Time: 2024-11-13 00:27:36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "User Embeddings...: 11it [00:00, 1463.10it/s]\n",
      "Anime Embeddings...: 100%|██████████| 25/25 [00:00<00:00, 245.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_embeddings.shape=(5408, 256) anime_embeddings.shape=(256, 12294)\n",
      "Commence God Operation\n",
      "Commence Big Sort Energy\n",
      "End Time: 2024-11-13 00:27:37\n",
      "This model took 1.7796 seconds.\n",
      "Out of an optimal score of 1.0, you scored 0.0256.\n",
      "Your DEI score is 20757.1826.\n",
      "Your Pseudo-IOU score is 0.0365.\n",
      ">>8|0.4093528985977173|{\"runtime\": 1.7796058654785156, \"ndcg\": 0.025633769926023335, \"diversity_score\": 20757.182589833086, \"pseudo_iou\": 0.03653846153846154}<<\n",
      "Epoch 10 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:0.356, +:2.047, -:-0.919:  89%|████████▊ | 94/106 [00:07<00:01, 11.93it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model_config \u001b[38;5;241m|\u001b[39m auxiliary_args\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m Models\u001b[38;5;241m.\u001b[39mfrom_string(args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupper())(datamodule\u001b[38;5;241m=\u001b[39mdatamodule, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_config)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m metrics \u001b[38;5;241m=\u001b[39m testbench\u001b[38;5;241m.\u001b[39mfull_evaluation(model)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\dev\\projects\\cmu\\CMU_10718\\src\\recommender\\tower_recommender.py:138\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_from:\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping training because model is loaded...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\James\\miniconda3\\envs\\cmu_10718\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\James\\miniconda3\\envs\\cmu_10718\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\James\\miniconda3\\envs\\cmu_10718\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\James\\miniconda3\\envs\\cmu_10718\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\James\\miniconda3\\envs\\cmu_10718\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\dev\\projects\\cmu\\CMU_10718\\src\\recommender\\tower_recommender.py:313\u001b[0m, in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32mc:\\dev\\projects\\cmu\\CMU_10718\\src\\utils\\data\\data_classes.py:237\u001b[0m, in \u001b[0;36mUser.sample_negative\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnegative_cais):\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot sample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m negative items from pool of size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnegative_cais)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m     )\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnegative_cais\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "auxiliary_args = {\n",
    "    \"n_users\": datamodule.max_user_count,\n",
    "    \"n_anime\": datamodule.max_anime_count,\n",
    "}\n",
    "model_config = model_config | auxiliary_args\n",
    "model = Models.from_string(args[\"model\"].upper())(datamodule=datamodule, **model_config)\n",
    "\n",
    "model.train()\n",
    "\n",
    "metrics = testbench.full_evaluation(model)\n",
    "with open(os.path.join(output_dir, \"output.txt\"), \"w\") as f:\n",
    "    for k, v in metrics.items():\n",
    "        if type(v) == np.ndarray:\n",
    "            continue\n",
    "        f.write(f\"{k}: {v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores.shape=(5408, 12294)\n",
      "48669\n"
     ]
    }
   ],
   "source": [
    "scores = metrics[\"scores\"]\n",
    "shows = np.argsort(-scores, axis=1)\n",
    "print(f\"{scores.shape=}\")\n",
    "test_cuids = datamodule.test_cuids\n",
    "first = test_cuids[0]\n",
    "print(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([0])],\n",
       " [tensor([2855, 4551,  760, 1087, 3978, 3560,  425, 3337,  449, 2620])],\n",
       " [tensor([ 1469,   596,  4644,  9903,   105,  7615,  5438,  4645,   287,  7656,\n",
       "          10739,  5982,  5852,  2715,  6476,  5459,  9709,  2710,  9693,  3762])])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get positive recommendations\n",
      "Average score: -0.023083681240677834\n",
      "Average scores of positive: 0.2732205390930176\n",
      "Ranks: [  942  1053  1121  1182  1508  1638  1653  1738  1810  1882  1986  2258\n",
      "  2468  2603  2701  2722  2939  3039  3373  3445  3721  3749  3767  3851\n",
      "  4314  4431  4539  4561  4678  4865  5073  5397  5399  5450  5525  5787\n",
      "  6015  6149  6237  6379  6436  6847  7479  7493  7703  7724  8118  8174\n",
      "  8190  8866  8905  9056  9212  9428  9566  9730  9928  9956 10371 10379\n",
      " 10544 11243 11678 11712 11933 12157]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Get positive recommendations\")\n",
    "positives_for_first = datamodule.canonical_user_mapping[first].preserved_cais\n",
    "print(f\"Average score: {scores[0].mean()}\")\n",
    "print(f\"Average scores of positive: {scores[0][positives_for_first].mean()}\")\n",
    "shows_in_preserved = np.isin(shows[0], positives_for_first)\n",
    "ranks = np.nonzero(shows_in_preserved)[0]\n",
    "print(f\"Ranks: {ranks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 0\n",
      "[0] - [13.575464248657227]: Rockman.EXE Stream, [1] - [13.480500221252441]: Kumori Nochi Hare, [2] - [12.464479446411133]: Hwanggeum Cheolin, [3] - [11.939308166503906]: Himawari no You ni, [4] - [11.854948997497559]: Aniyome, User 1\n",
      "[0] - [13.505234718322754]: Nyamen: Tenkai Daiichi Joshi Koukou Bunka Matsuri Tokubetsu Eizou, [1] - [12.39642333984375]: Ashita no Joe 2 (Movie), [2] - [12.390143394470215]: Angelium, [3] - [12.329965591430664]: Kizuoibito, [4] - [12.233551979064941]: Sanrio Anime Sekai Meisaku Gekijou, User 2\n",
      "[0] - [11.632704734802246]: Ghost Messenger Movie, [1] - [10.786734580993652]: Tondera House no Daibouken, [2] - [10.354955673217773]: Urusei Yatsura Movie 6: Itsudatte My Darling, [3] - [10.296066284179688]: Cofun Gal no Coffy: Cofunderella, [4] - [10.26324462890625]: Soul Worker: Your Destiny Awaits, User 3\n",
      "[0] - [14.320096015930176]: Kaijuu no Ballad, [1] - [13.771485328674316]: Fuyu no Yoru no Ohanashi, [2] - [13.52220630645752]: Sansha Sanyou, [3] - [13.106348037719727]: Candy Boy Episode: EX01 - Mirai Yohouzu, [4] - [12.435722351074219]: Nice to See You, User 4\n",
      "[0] - [10.367541313171387]: Lady Georgie, [1] - [9.951247215270996]: Narutaru: Mukuro Naru Hoshi Tama Taru Ko, [2] - [9.804712295532227]: Bubblegum Crash, [3] - [9.743983268737793]: Mi-da-ra, [4] - [9.672224044799805]: Legend of Lemnear: Kyokuguro no Tsubasa Valkisas, "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"User {i}\")\n",
    "    for j in range(5):\n",
    "        print(\n",
    "            f\"[{j}] - [{scores[i, shows[i,j]]}]: {datamodule.canonical_anime_mapping[shows[i, j]].name}, \",\n",
    "            end=\"\",\n",
    "        )\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48669\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "print(len(datamodule.canonical_user_mapping[first].preserved_cais))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.isinf(scores[0]).sum()=np.int64(12294)\n",
      "len(scores[0])=12294\n"
     ]
    }
   ],
   "source": [
    "print(f\"{np.isinf(scores[0]).sum()=}\")\n",
    "print(f\"{len(scores[0])=}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmu_10718",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
